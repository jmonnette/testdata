{
  "DateofBirth","1978-06-29",
  "ECOACode(1,2,3,5,7,T,X,W,Z)":"3",
  "FirstLineofAddress":"1234 Main St.",
  "FirstName":"John",
  "MiddleName":"David",
  "Postal-ZipCode":"30306",
  "ResidenceCode":"1",
  "SecondLineofAddress":"",
  "SocialSecurityNumber":"123-45-6789",
  "State":"GA",
  "Surname":"Smith",
  "TelephoneNumber":"774-513-8809",
  "Accounts(0,20)":[
    {
      "ProcessingIndicator":1,
      "TimeStamp":"2023-01-01",
      "CorrectionIndicator(0,1)":0,
      "IdentificationNumber[Char(20)]":"12345678910111213",
      "CycleIdentifier":"AB",
      "ConsumerAccountNumber[Char(30)]":"12345678910111213",
      "PortfolioType(R,I,O,M,C)":"R",
      "AccountType(00,01,02,03,04,05,10,11,13,17,20,90,0A,3A)":"04",
      "DateOpened":"2010-01-01",
      "CreditLimit":1000.00,
      "HighestCreditorOriginalLoanAmount":2000.00,
      "TermsDuration":"12",
      "TermsFrequency(D,P,W,B,E,M,L,Q,T,S,Y)":"D",
      "ScheduledMonthlyPaymentAmount":100.00,
      "ActualPaymentAmount":100.00,
      "PaymentHistoryProfile":"",
      "SpecialComment(M,AP,BL,CI,AM)":"",
      "ComplianceConditionCode(XB,XC,XF,XG,XH,XR)":"XB",
      "CurrentBalance":10000.00,
      "AmountPastDue":10.57,
      "OriginalCharge-offAmount":20.00,
      "DateofAccountInformation":"2023-01-01".
      "FCRACompliance-DateofFirstDelinquency":"2023-01-01",
      "DateClosed("1950-01-01","2023-01-01")":"2023-01-01",
      "DateofLastPayment:"2023-01-01",
      "InterestTypeIndicator(F,V)":"F"
      "ConsumerTransactionType":"A",
      "GenerationCode":"",
      "ConsumerInformationIndicator(T,U)":"T",
      "CountryCode":"US",
      "City":"Chicago",
      "AddressIndicator":"A",
      "AccountStatus(11,13,61,62,63,64,71,78,80,82,83,84,93,95,96,97,DA,DF)":"11"
    }
  ]
}

#################

- In addition to the values provided, the SpecialComment field can also be blank.
- All Balance and Amount fields should be random amounts including 0.
- CountryCode should be an ISO-3166-1 two-letter country code.
- TimeStamp should be a date and time field within the last 90 days
- DateClosed can be blank
- MiddleName can be blank or a randomly generated name
- DateOpened must be an earlier date than DateClosed
- AccountType should be populated using a function called portfolio_type_to_account_type in a module called metro2.  This function takes the PortfolioType as a parameter.

#################

Using the JSON object as a template, generate Python3 code that creates an array of JSON objects with different values.

The number of objects to include in the array is specified via a command-line parameter called numObjects.

The Python code should use the Faker library to generate realistic data.
Use the JSON field names and example data to infer the type of data to generate.
You can also infer business rules about the data from the field names.
Unless specifically stated, the values for all fields should be randomly generated (i.e., there should be no hardcoded values unless specifically stated)

For array fields, the digits in parentheses in the field name indicate the range of array sizes to generate.
For example, "(1,3)" indicates that there should be 1 to 3 objects in the generated array.
Always exclude this parenthetical from the field name in the generated output JSON.

For date fields, the dates in parentheses in the field name indicate the valid date range for the field.
For example, "(2002-01-01,2003-06-30)" indicates that the date must be between January 1, 2002 and June 30, 2003.
Always exclude this parenthetical from the field name in the generated output JSON.
Also, you should do your best to infer the implied order of dates based on the field names and generate dates according to the implied order.
For example, a field called start should be earlier than a field called end.  A field called opened should be earlier than a field called closed.

For text fields, the values in parentheses indicate the set of valid values for the field.
You should choose only from these values when generating the data for the field.
Always exclude this parenthetical from the field name in the generated output JSON.

If the field name contains square brackets, "[]", the value between the square brackets indicates the data type for the field.
Make sure that the generated value matches the data type when specified.
If the data type is not specified, then generated data type must match the data type of the example value.
Always exclude the brackets and bracketed text from the field name in the output.

Remember, the part of the parentheticals in the template JSON field names in parentheses are not to be included in the JSON output.
Remember, the brackets and bracketed text in the field names are not to be included in the JSON output.
Remember also to make sure there are no hardcoded values in the output JSON unless specifically asked for.

{{Additional Description}}

The Python code should write the JSON to a file called {{Output File Name}}.

JSON:

{{JSON Example}}

##################
OBJECTIVE

Allow a non-developer to generate realistic and valid test data for any data set by specifying a JSON object that describes the data format to be generated.

The LLM should infer the data type and expected data values from the name of each field.

For arrays, the user can specify the desired array length range by including it in parentheses in the field name.

For text fields, the user can specify list of valid values by including it in parentheses in the field name.

For date fields, the user can specify the range of valid dates by including it in parentheses in the field name.

The user can also specify additional business rules in plain English to help the LLM understand the expected output.

It is important to iterate over the output of the LLM and add additional rules to the prompt to fine tune the data generated by the script.

SUMMARY

In this conversation, we worked on creating Python scripts that generate arrays of JSON objects and CSV files with randomly sampled data. We used the Faker library to create diverse and realistic data for different fields.

From the initial example of a JSON object, we inferred the types of data needed for each field, implementing rules for number ranges, date ranges, and specific text options.

We accommodated arrays, ensuring generated arrays had lengths within specified ranges. We also managed date fields well, generating dates within specified ranges and following implied chronology (i.e., start dates are earlier than end dates).

We generated suitable data for text field, picking from sets of valid choices. For balance and amount fields, we ensured random outputs, including zero.

When outputting to JSON, we ensured the field names in the output didn't include any of the original parenthetical text from the template JSON. Similarly, when outputting to CSV, we included an new ID field to link consumer and account information.

Certain custom functions were needed (such as portfolio_type_to_account_type), the definitions of which were not provided in this scope of work, but placeholders were appropriately included.

Functionality was added to take command-line parameters, specifying the number of JSON objects or CSV entries to create, and to write generated data to files like metro2.json, consumer.csv, and accounts.csv.

#######################

  Our goal is to create a Python3 script that will validate a JSON file and produce a list of validation errors contained in the input.

  The script should take an input file path and output file path as command line parameters.

  The script will iterate all of the files in the path, validate each file, and produce a validation report per input file in the output folder.


#######################

  Using the JSON object as a template, generate a Python3 validation script using Cerberus.
  The script will be used to validate JSON documents similar to the example.

  Your only task for now is to generate the Cerberus schema.  We'll get to the rest of the script later.

  Use the JSON field names and example values to infer the data types.
  You can also infer business rules about the data from the field names.

  Where possible based on inference from the field name, include regex pattern validations.  '
  This should include all date and date-time fields.

  For array fields, the digits in parentheses in the field name indicate the range of array sizes to generate.
  For example, "(1,3)" indicates that there should be 1 to 3 objects in the array.
  Always exclude this parenthetical from the field name in the generated schema as it doesn't exist in the JSON to be validated.

  For date fields, the dates in parentheses in the field name indicate the valid date range for the field.
  For example, "(2002-01-01,2003-06-30)" indicates that the date must be between January 1, 2002 and June 30, 2003.
  Always exclude this parenthetical from the field name in the generated schema.
  If a date range is specified, assume that a custom validator exists that can validate the range.  The range should be included in the schema as a field called date_range.
  If a date range is not specified, do not include the date_range field.

  For text fields, the values in parentheses indicate the set of valid values for the field.
  These are the only values allowed for the field.
  Always exclude this parenthetical from the field name in the generated schema.

  If the field name contains square brackets, "[]", the value between the square brackets indicates the data type for the field.
  Use this value to specify the data type in the generated schema.  If not specified, then infer the data type from the example value and the field name.
  Include regex patterns to validate field lengths based on the specified data types.
  Always exclude the brackets and bracketed text from the field name in the schema.

  Remember, the part of the parentheticals in the template JSON field names in parentheses are not to be included in the schema.
  Remember, the brackets and bracketed text in the field names are not to be included in the schema.
  Remember, you must output the complete Cerberus and valid Cerberus schema.  Regex validations use a field called "regex".

  Please consider these additional rules when generating the schema:

  {{Additional Description}}

  JSON:

  {{JSON Example}}

 - In addition to the values provided, the SpecialComment field can also be blank
 - All Balance and Amount fields should greater than or equal to 0
 - CountryCode should be validated using a validator called country
 - TimeStamp should be a date-time field within the last 90 days
 - DateClosed is not required
 - MiddleName is not required
 - State should be a validated using a custom validator called us_state


Now let's implement a custom Cerberus validator to handle the following use cases:

1) date_range: Validate that the date is between the two values passed in as a list
2) country: Validate that the country is a valid 2 character ISO-3166-1 code using Python code instead of an enumeration
3) us_state: Validate that the state is a valid 2 character US postal abbreviation using Python code instead of an enumeration
